---
title: "Confidence estimation advice properties"
author: "Matt Jaquiery (matt.jaquiery@psy.ox.ac.uk)"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
    css: ../src/writeUp.css
    includes:
      after_body: ../src/toc_menu.html
  html_notebook:
    toc: yes
    toc_depth: 3
    css: ../src/writeUp.css
    includes:
      after_body: ../src/toc_menu.html
editor_options:
  chunk_output_type: inline
---

December 2019

[Script run `r Sys.time()`]

```{r}
library(tidyverse)

theme_set(
  theme_light() + 
    theme(panel.grid.minor = element_blank(),
          panel.grid.major.x = element_blank())
  )
```

# Background

In the binary version of the dates task we draw the anchor dates from a normal distribution around the actual date, excluding the exact date. This gives a binary answer to the question of whether the actual date is before or after the anchor date. 

Advisors' advice is generated by having the advisors make noisy guesses at the date (another normal distribution around the actual date), and then their confidence is established by scaling the difference between the actual and guessed date according to the advisor's confidence characteristics. 

The question for simulation here is how the standard deviations of the two distributions interrelate to produce accuracy rates for the advisors. 

The anchor places a marker on a standard distribution, dividing the distribution into a left-hand part which constitutes 'before' estimates and a right-hand part which consititutes 'after' estimates. For an anchor date after the actual date (given symmetry, it's trivial to reverse this to deal with before anchors), any date up to the anchor date will be equivalent in terms of the accuracy of the binary answer (correct).

Where both standard deviations are the same, the problem is illustrated thus:

```{r}
n <- 100000
x <- tibble(
  x = seq(-3, 3, .01),
  cd = dnorm(x),
  ans = if_else(x < 2, "correct", "wrong")
)

x %>% ggplot(aes(x = x, y = cd)) +
  geom_col(aes(fill = ans)) + 
  annotate(geom = "rect", fill = "black", 
           xmin = -.01, ymin = 0, xmax = .01, ymax = .2) +
  annotate(geom = "label", x = 0, y = .22, label = "actual date") +
  annotate(geom = "rect", fill = "black", 
           xmin = 1.99, ymin = 0, xmax = 2.01, ymax = .2) +
  annotate(geom = "label", x = 2, y = .22, label = "e.g. anchor date") +
  scale_fill_discrete(h.start = 180, name = "advisor guess")
```

The question can be generalised to asking: given two samples from two independent normal distributions, what is the probability that the score from the first one is more extreme than the score for the second one? This is intuitively a function of the standard deviations of these distributions: if they were equal, the probability of a less extreme result the second time around is the cumulative density function for the first result.

**Note** a 'less extreme' result includes massive errors in the opposite direction.

# Equal SD

For the example above, we can simulate some data.

```{r}
n <- 1000

x <- tibble(
  i = 1:n,
  anchor = rnorm(n),
  guess = rnorm(n),
  correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor)
)

x %>% gather("source", "estimate", anchor:guess) %>% 
  ggplot(aes(x = source, y = estimate, colour = correct)) +
  geom_violin(fill = NA, colour = "black", size = 1.5) + 
  geom_line(aes(group = i), alpha = .1) +
  facet_wrap(~correct, labeller = label_both)

x %>% summarise(pCorrect = mean(correct))
```

When the SDs are equal we get a mean correctness of .75. This makes sense because there's a 50% chance that the anchor and the guess will be on opposite sides of the actual date (0), meaning the advice is correct. In the half of cases where the anchor and guess are on the same side, they're as likely as one another to have scores more extreme than any given value, so the probability the anchor is more extreme is .5. The 50% + (50% of the remaining 50%) = 75%. 

# Advice twice as precise (half SD)

```{r}
n <- 1000

x <- tibble(
  i = 1:n,
  anchor = rnorm(n, sd = 8),
  guess = rnorm(n, sd = 4),
  correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor)
)

x %>% gather("source", "estimate", anchor:guess) %>% 
  ggplot(aes(x = source, y = estimate, colour = correct)) +
  geom_violin(fill = NA, colour = "black", size = 1.5) + 
  geom_line(aes(group = i), alpha = .1) +
  facet_wrap(~correct, labeller = label_both)

x %>% summarise(pCorrect = mean(correct))
```

# Titrating to 70%

```{r}

n <- 1000
r <- 100

d <- NULL

for (rep in 1:r) {
  x <- tibble(
    s = seq(1, 20, .5)
  ) %>% 
    group_by(s) %>%
    do(df = tibble(
      i = 1:n,
      anchor = rnorm(n, sd = 8),
      guess = rnorm(n, sd = .$s),
      correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor)
    ) %>%
      summarise(pCorrect = mean(correct))) %>%
    unnest(df)
  
  d <- rbind(d, x)
}

d %>% group_by(s) %>% summarise(pCorrect = mean(pCorrect))

ggplot(d, aes(x = s, y = pCorrect, group = s)) +
  stat_summary(geom = "point", fun.y = mean) +
  stat_summary(geom = "errorbar", fun.data = mean_cl_normal, width = 0) + 
  geom_hline(yintercept = .7, linetype = "dashed") +
  scale_y_continuous(limits = c(0, 1)) +
  labs(x = "Advisor SD",
       caption = paste("Estimation based on", 
                       r, "repetitions of", 
                       n, "samples.")) +
  annotate(geom = "text", x = 15, y = .9, label = "Anchor SD = 8.0") +
  annotate(geom = "label", x = 3, y = .7, label = "70% accuracy")
```

# Confidence

We want to provide advisors who are equally accurate, and whose confidence is equally useful at determining p(correct) when known, while differing in their absolute confidence. The first question is whether we can do this by simply varying the SD of the advisors.

## Confidence of advisor with SD = Anchor SD

An advisor's confidence is taken with reference to a limit. The limit defines the year distance between guess and anchor at which the advisor is 100% confidence. The advisor's confidence increases linearly as the distance between guess and anchor grows towards the limit. 

```{r}

n <- 1000
limit <- 30

x <- tibble(
  i = 1:n,
  anchor = rnorm(n, sd = 8),
  guess = rnorm(n, sd = 8),
  correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor),
  confidence = pmin(100, pmax(0, abs(guess - anchor) / limit * 100))
)

ggplot(x, aes(x = anchor, y = guess, colour = confidence)) + 
  geom_point() +
  coord_fixed()

ggplot(x, aes(x = confidence)) + 
  geom_histogram(bins = 10)

f <- function(binRight, binWidth, data) {
  data %>% 
    filter(confidence > binRight - binWidth, confidence <= binRight) %>%
    pull(correct) %>%
    mean()
}

pCorrect <- tibble(
  bin = seq(10, 100, 10),
  pCor = map(bin, ~ f(., 10, x))
) %>% unnest_legacy()

ggplot(pCorrect, aes(x = bin / 100, y = pCor)) +
  geom_abline(linetype = 'dashed', intercept = 0, slope = 1) +
  geom_point(shape = 4) +
  geom_line() +
  coord_fixed() +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +
  scale_x_continuous(limits = c(0, 1), expand = c(0, 0)) +
  labs(x = 'confidence / 100', y = 'p(correct)')

x <- x %>%
  mutate(bin = map(confidence, ~ 10 * min(which(seq(10, 100, 10) >= .)))) %>%
  unnest_legacy() %>%
  left_join(pCorrect, by = 'bin')

```

The advisors are thus pretty neatly distributed with a half-normal distribution of confidence centred on 0 and an SD dependent on both the limit and the advisor's accuracy. We'll now see how these distributions behave given differences in the limit and advisor accuracy.

## Change in confidence given change in SD ratio

```{r}
limits <- c(20, 30, 40, 50)
sds <- c(2, 4, 8, 16)

n <- 1000

x <- crossing(
  i = 1:n,
  limit = limits,
  sd = sds
)

x <- x %>%
  mutate(
    anchor = rnorm(n(), sd = 8),
    guess = rnorm(n(), sd = sd),
    correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor),
    confidence = round(pmin(100, pmax(0, abs(guess - anchor) / limit * 100)))
)

ggplot(x, aes(x = anchor, y = guess, colour = confidence)) + 
  geom_point() +
  coord_fixed() +
  scale_x_continuous(limits = c(-100, 100)) +
  scale_y_continuous(limits = c(-100, 100)) +
  facet_grid(sd ~ limit, labeller = label_both)

ggplot(x, aes(x = confidence)) + 
  geom_histogram(bins = 10) +
  facet_grid(sd ~ limit, labeller = label_both, scales = 'free_y')

x <- x %>%
  mutate(bin = map(confidence, ~ 10 * min(which(seq(10, 100, 10) >= .)))) %>%
  unnest_legacy() %>%
  nest(data = c(-bin, -limit, -sd)) %>%
  mutate(pCor = map(data, ~ mean(.x$correct))) %>%
  unnest_legacy(pCor) %>%
  unnest_legacy()

x %>%
  select(bin, limit, sd, pCor) %>%
  unique() %>%
  ggplot(aes(x = bin / 100, y = pCor)) +
  geom_abline(linetype = 'dashed', intercept = 0, slope = 1) +
  geom_point(shape = 4) +
  geom_line() +
  coord_fixed() +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  labs(x = 'confidence / 100', y = 'p(correct)') +
  facet_grid(sd ~ limit, labeller = label_both)

```

## Advisor confidence adjustment

There appear to be two reasonable strategies for modifying advice confidence while maintaining metacognitive characteristics: a) shifting the distribution by adding a constant and b) using more of the scale.

### Shifting the distribution

```{r}

agents <- c('lowConf', 'highConf')
biases <- c(0, 30)
limit <- 30

n <- 1000

x <- crossing(
  i = 1:n,
  agent = agents
)

x <- x %>%
  mutate(
    bias = if_else(agent == 'lowConf', biases[1], biases[2]),
    anchor = rnorm(n(), sd = 8),
    guess = rnorm(n(), sd = 8),
    correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor),
    confidence = round(
      pmin(100, pmax(0, abs(guess - anchor) / limit * 100 + bias))
      )
)

ggplot(x, aes(x = anchor, y = guess, colour = confidence)) + 
  geom_point() +
  coord_fixed() +
  scale_x_continuous(limits = c(-100, 100)) +
  scale_y_continuous(limits = c(-100, 100)) +
  facet_wrap(~agent, labeller = label_both)

ggplot(x, aes(x = confidence, fill = agent)) + 
  geom_histogram(bins = 10, alpha = .5, position = position_identity())

x <- x %>%
  mutate(bin = map(confidence, ~ 10 * min(which(seq(10, 100, 10) >= .)))) %>%
  unnest_legacy() %>%
  nest(data = c(-bin, -agent)) %>%
  mutate(pCor = map(data, ~ mean(.x$correct))) %>%
  unnest_legacy(pCor) %>%
  unnest_legacy()

x %>%
  select(bin, agent, pCor) %>%
  unique() %>%
  ggplot(aes(x = bin / 100, y = pCor, colour = agent)) +
  geom_abline(linetype = 'dashed', intercept = 0, slope = 1) +
  geom_point(shape = 4) +
  geom_line() +
  coord_fixed() +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  labs(x = 'confidence / 100', y = 'p(correct)')

```

### Using more of the scale

This is achieved by changing the limit for an advisor.

```{r}
agents <- c('lowConf', 'highConf')
limits <- c(25, 40)

n <- 1000

x <- crossing(
  i = 1:n,
  agent = agents
)

x <- x %>%
  mutate(
    limit = if_else(agent == 'lowConf', limits[1], limits[2]),
    anchor = rnorm(n(), sd = 8),
    guess = rnorm(n(), sd = 8),
    correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor),
    confidence = round(
      pmin(100, pmax(0, abs(guess - anchor) / limit * 100))
      )
)

ggplot(x, aes(x = anchor, y = guess, colour = confidence)) + 
  geom_point() +
  coord_fixed() +
  scale_x_continuous(limits = c(-100, 100)) +
  scale_y_continuous(limits = c(-100, 100)) +
  facet_wrap(~agent, labeller = label_both)

ggplot(x, aes(x = confidence, fill = agent)) + 
  geom_histogram(bins = 10, alpha = .5, position = position_identity())

x <- x %>%
  mutate(bin = map(confidence, ~ 10 * min(which(seq(10, 100, 10) >= .)))) %>%
  unnest_legacy() %>%
  nest(data = c(-bin, -agent)) %>%
  mutate(pCor = map(data, ~ mean(.x$correct))) %>%
  unnest_legacy(pCor) %>%
  unnest_legacy()

x %>%
  select(bin, agent, pCor) %>%
  unique() %>%
  ggplot(aes(x = bin / 100, y = pCor, colour = agent)) +
  geom_abline(linetype = 'dashed', intercept = 0, slope = 1) +
  geom_point(shape = 4) +
  geom_line() +
  coord_fixed() +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  labs(x = 'confidence / 100', y = 'p(correct)')
```

## Crush and shift

Another option for modifying confidence judgements is to have advisors make them on a smaller scale and then shift the resulting confidence judgements by some amount.

```{r}

agents <- c('lowConf', 'highConf')
biases <- c(0, 30)
crush <- 30
limit <- 30

n <- 1000

x <- crossing(
  i = 1:n,
  agent = agents
)

x <- x %>%
  mutate(
    bias = if_else(agent == 'lowConf', biases[1], biases[2]),
    anchor = rnorm(n(), sd = 8),
    guess = rnorm(n(), sd = 8),
    correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor),
    confidence = round(
      pmin(100, pmax(0, abs(guess - anchor) / limit * (100 - crush) + bias))
      )
)

ggplot(x, aes(x = anchor, y = guess, colour = confidence)) + 
  geom_point() +
  coord_fixed() +
  scale_x_continuous(limits = c(-100, 100)) +
  scale_y_continuous(limits = c(-100, 100)) +
  facet_wrap(~agent, labeller = label_both)

ggplot(x, aes(x = confidence, fill = agent)) + 
  geom_histogram(bins = 10, alpha = .5, position = position_identity())

x <- x %>%
  mutate(bin = map(confidence, ~ 10 * min(which(seq(10, 100, 10) >= .)))) %>%
  unnest_legacy() %>%
  nest(data = c(-bin, -agent)) %>%
  mutate(pCor = map(data, ~ mean(.x$correct))) %>%
  unnest_legacy(pCor) %>%
  unnest_legacy()

x %>%
  select(bin, agent, pCor) %>%
  unique() %>%
  ggplot(aes(x = bin / 100, y = pCor, colour = agent)) +
  geom_abline(linetype = 'dashed', intercept = 0, slope = 1) +
  geom_point(shape = 4) +
  geom_line() +
  coord_fixed() +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  labs(x = 'confidence / 100', y = 'p(correct)')

```
