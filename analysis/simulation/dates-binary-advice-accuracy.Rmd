---
title: "Confidence estimation advice properties"
author: "Matt Jaquiery (matt.jaquiery@psy.ox.ac.uk)"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
    css: ../src/writeUp.css
    includes:
      after_body: ../src/toc_menu.html
  html_notebook:
    toc: yes
    toc_depth: 3
    css: ../src/writeUp.css
    includes:
      after_body: ../src/toc_menu.html
editor_options:
  chunk_output_type: inline
---

December 2019

[Script run `r Sys.time()`]

```{r}
library(tidyverse)

theme_set(
  theme_light() + 
    theme(panel.grid.minor = element_blank(),
          panel.grid.major = element_blank())
  )
```

# Background

In the binary version of the dates task we draw the anchor dates from a normal distribution around the actual date, excluding the exact date. This gives a binary answer to the question of whether the actual date is before or after the anchor date. 

Advisors' advice is generated by having the advisors make noisy guesses at the date (another normal distribution around the actual date), and then their confidence is established by scaling the difference between the actual and guessed date according to the advisor's confidence characteristics. 

The question for simulation here is how the standard deviations of the two distributions interrelate to produce accuracy rates for the advisors. 

The anchor places a marker on a standard distribution, dividing the distribution into a left-hand part which constitutes 'before' estimates and a right-hand part which consititutes 'after' estimates. For an anchor date after the actual date (given symmetry, it's trivial to reverse this to deal with before anchors), any date up to the anchor date will be equivalent in terms of the accuracy of the binary answer (correct).

Where both standard deviations are the same, the problem is illustrated thus:

```{r}
n <- 100000
x <- tibble(
  x = seq(-3, 3, .01),
  cd = dnorm(x),
  ans = if_else(x < 2, "correct", "wrong")
)

x %>% ggplot(aes(x = x, y = cd)) +
  geom_col(aes(fill = ans)) + 
  annotate(geom = "rect", fill = "black", 
           xmin = -.01, ymin = 0, xmax = .01, ymax = .2) +
  annotate(geom = "label", x = 0, y = .22, label = "actual date") +
  annotate(geom = "rect", fill = "black", 
           xmin = 1.99, ymin = 0, xmax = 2.01, ymax = .2) +
  annotate(geom = "label", x = 2, y = .22, label = "e.g. anchor date") +
  scale_fill_discrete(h.start = 180, name = "advisor guess")
```

The question can be generalised to asking: given two samples from two independent normal distributions, what is the probability that the score from the first one is more extreme than the score for the second one? This is intuitively a function of the standard deviations of these distributions: if they were equal, the probability of a less extreme result the second time around is the cumulative density function for the first result.

**Note** a 'less extreme' result includes massive errors in the opposite direction.

# Equal SD

For the example above, we can simulate some data.

```{r}
n <- 1000

x <- tibble(
  i = 1:n,
  anchor = rnorm(n),
  guess = rnorm(n),
  correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor)
)

x %>% gather("source", "estimate", anchor:guess) %>% 
  ggplot(aes(x = source, y = estimate, colour = correct)) +
  geom_violin(fill = NA, colour = "black", size = 1.5) + 
  geom_line(aes(group = i), alpha = .1) +
  facet_wrap(~correct, labeller = label_both)

x %>% summarise(pCorrect = mean(correct))
```

When the SDs are equal we get a mean correctness of .75. This makes sense because there's a 50% chance that the anchor and the guess will be on opposite sides of the actual date (0), meaning the advice is correct. In the half of cases where the anchor and guess are on the same side, they're as likely as one another to have scores more extreme than any given value, so the probability the anchor is more extreme is .5. The 50% + (50% of the remaining 50%) = 75%. 

# Advice twice as precise (half SD)

```{r}
n <- 1000

x <- tibble(
  i = 1:n,
  anchor = rnorm(n, sd = 8),
  guess = rnorm(n, sd = 4),
  correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor)
)

x %>% gather("source", "estimate", anchor:guess) %>% 
  ggplot(aes(x = source, y = estimate, colour = correct)) +
  geom_violin(fill = NA, colour = "black", size = 1.5) + 
  geom_line(aes(group = i), alpha = .1) +
  facet_wrap(~correct, labeller = label_both)

x %>% summarise(pCorrect = mean(correct))
```

# Titrating to 70%

```{r}

n <- 1000
r <- 100

d <- NULL

for (rep in 1:r) {
  x <- tibble(
    s = seq(1, 20, .5)
  ) %>% 
    group_by(s) %>%
    do(df = tibble(
      i = 1:n,
      anchor = rnorm(n, sd = 8),
      guess = rnorm(n, sd = .$s),
      correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor)
    ) %>%
      summarise(pCorrect = mean(correct))) %>%
    unnest(df)
  
  d <- rbind(d, x)
}

d %>% group_by(s) %>% summarise(pCorrect = mean(pCorrect))

ggplot(d, aes(x = s, y = pCorrect, group = s)) +
  stat_summary(geom = "point", fun.y = mean) +
  stat_summary(geom = "errorbar", fun.data = mean_cl_normal, width = 0) + 
  geom_hline(yintercept = .7, linetype = "dashed") +
  scale_y_continuous(limits = c(0, 1)) +
  labs(x = "Advisor SD",
       caption = paste("Estimation based on", 
                       r, "repetitions of", 
                       n, "samples.")) +
  annotate(geom = "text", x = 15, y = .9, label = "Anchor SD = 8.0") +
  annotate(geom = "label", x = 3, y = .7, label = "70% accuracy")
```

# Confidence

We want to provide advisors who are equally accurate, and whose confidence is equally useful at determining p(correct) when known, while differing in their absolute confidence. The first question is whether we can do this by simply varying the SD of the advisors.

## Confidence of advisor with SD = Anchor SD

An advisor's confidence is taken with reference to a limit. The limit defines the year distance between guess and anchor at which the advisor is 100% confidence. The advisor's confidence increases linearly as the distance between guess and anchor grows towards the limit. 

```{r}

n <- 1000
limit <- 30

x <- tibble(
  i = 1:n,
  anchor = rnorm(n, sd = 8),
  guess = rnorm(n, sd = 8),
  correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor),
  confidence = pmin(100, pmax(0, abs(guess - anchor) / limit * 100))
)

ggplot(x, aes(x = anchor, y = guess, colour = confidence)) + 
  geom_point() +
  coord_fixed()

ggplot(x, aes(x = confidence)) + 
  geom_histogram(bins = 10)

f <- function(binRight, binWidth, data) {
  data %>% 
    filter(confidence > binRight - binWidth, confidence <= binRight) %>%
    pull(correct) %>%
    mean()
}

pCorrect <- tibble(
  bin = seq(10, 100, 10),
  pCor = map(bin, ~ f(., 10, x))
) %>% unnest_legacy()

ggplot(pCorrect, aes(y = bin / 100, x = pCor)) +
  geom_abline(linetype = 'dashed', intercept = 0, slope = 1) +
  geom_point(shape = 4) +
  geom_line() +
  coord_fixed() +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +
  scale_x_continuous(limits = c(0, 1), expand = c(0, 0)) +
  labs(y = 'confidence / 100', x = 'p(correct)')

x <- x %>%
  mutate(bin = map(confidence, ~ 10 * min(which(seq(10, 100, 10) >= .)))) %>%
  unnest_legacy() %>%
  left_join(pCorrect, by = 'bin')

```

The advisors are thus pretty neatly distributed with a half-normal distribution of confidence centred on 0 and an SD dependent on both the limit and the advisor's accuracy. We'll now see how these distributions behave given differences in the limit and advisor accuracy.

## Change in confidence given change in SD ratio

```{r}
limits <- c(20, 30, 40, 50)
sds <- c(2, 4, 8, 16)

n <- 1000

x <- crossing(
  i = 1:n,
  limit = limits,
  sd = sds
)

x <- x %>%
  mutate(
    anchor = rnorm(n(), sd = 8),
    guess = rnorm(n(), sd = sd),
    correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor),
    confidence = round(pmin(100, pmax(0, abs(guess - anchor) / limit * 100)))
)

ggplot(x, aes(x = anchor, y = guess, colour = confidence)) + 
  geom_point() +
  coord_fixed() +
  scale_x_continuous(limits = c(-100, 100)) +
  scale_y_continuous(limits = c(-100, 100)) +
  facet_grid(sd ~ limit, labeller = label_both)

ggplot(x, aes(x = confidence)) + 
  geom_histogram(bins = 10) +
  facet_grid(sd ~ limit, labeller = label_both, scales = 'free_y')

x <- x %>%
  mutate(bin = map(confidence, ~ 10 * min(which(seq(10, 100, 10) >= .)))) %>%
  unnest_legacy() %>%
  nest(data = c(-bin, -limit, -sd)) %>%
  mutate(pCor = map(data, ~ mean(.x$correct))) %>%
  unnest_legacy(pCor) %>%
  unnest_legacy()

x %>%
  select(bin, limit, sd, pCor) %>%
  unique() %>%
  ggplot(aes(y = bin / 100, x = pCor)) +
  geom_abline(linetype = 'dashed', intercept = 0, slope = 1) +
  geom_point(shape = 4) +
  geom_line() +
  coord_fixed() +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  labs(y = 'confidence / 100', x = 'p(correct)') +
  facet_grid(sd ~ limit, labeller = label_both)

```

## Advisor confidence adjustment

There appear to be two reasonable strategies for modifying advice confidence while maintaining metacognitive characteristics: a) shifting the distribution by adding a constant and b) using more of the scale.

### Shifting the distribution

```{r}

agents <- c('lowConf', 'highConf')
biases <- c(0, 30)
limit <- 30

n <- 1000

x <- crossing(
  i = 1:n,
  agent = agents
)

x <- x %>%
  mutate(
    bias = if_else(agent == 'lowConf', biases[1], biases[2]),
    anchor = rnorm(n(), sd = 8),
    guess = rnorm(n(), sd = 8),
    correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor),
    confidence = round(
      pmin(100, pmax(0, abs(guess - anchor) / limit * 100 + bias))
      )
)

ggplot(x, aes(x = anchor, y = guess, colour = confidence)) + 
  geom_point() +
  coord_fixed() +
  scale_x_continuous(limits = c(-100, 100)) +
  scale_y_continuous(limits = c(-100, 100)) +
  facet_wrap(~agent, labeller = label_both)

ggplot(x, aes(x = confidence, fill = agent)) + 
  geom_histogram(bins = 10, alpha = .5, position = position_identity())

x <- x %>%
  mutate(bin = map(confidence, ~ 10 * min(which(seq(10, 100, 10) >= .)))) %>%
  unnest_legacy() %>%
  nest(data = c(-bin, -agent)) %>%
  mutate(pCor = map(data, ~ mean(.x$correct))) %>%
  unnest_legacy(pCor) %>%
  unnest_legacy()

x %>%
  select(bin, agent, pCor) %>%
  unique() %>%
  ggplot(aes(y = bin / 100, x = pCor, colour = agent)) +
  geom_abline(linetype = 'dashed', intercept = 0, slope = 1) +
  geom_point(shape = 4) +
  geom_line() +
  coord_fixed() +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  labs(y = 'confidence / 100', x = 'p(correct)')

```

### Using more of the scale

This is achieved by changing the limit for an advisor.

```{r}
agents <- c('lowConf', 'highConf')
limits <- c(25, 40)

n <- 1000

x <- crossing(
  i = 1:n,
  agent = agents
)

x <- x %>%
  mutate(
    limit = if_else(agent == 'lowConf', limits[1], limits[2]),
    anchor = rnorm(n(), sd = 8),
    guess = rnorm(n(), sd = 8),
    correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor),
    confidence = round(
      pmin(100, pmax(0, abs(guess - anchor) / limit * 100))
      )
)

ggplot(x, aes(x = anchor, y = guess, colour = confidence)) + 
  geom_point() +
  coord_fixed() +
  scale_x_continuous(limits = c(-100, 100)) +
  scale_y_continuous(limits = c(-100, 100)) +
  facet_wrap(~agent, labeller = label_both)

ggplot(x, aes(x = confidence, fill = agent)) + 
  geom_histogram(bins = 10, alpha = .5, position = position_identity())

x <- x %>%
  mutate(bin = map(confidence, ~ 10 * min(which(seq(10, 100, 10) >= .)))) %>%
  unnest_legacy() %>%
  nest(data = c(-bin, -agent)) %>%
  mutate(pCor = map(data, ~ mean(.x$correct))) %>%
  unnest_legacy(pCor) %>%
  unnest_legacy()

x %>%
  select(bin, agent, pCor) %>%
  unique() %>%
  ggplot(aes(y = bin / 100, x = pCor, colour = agent)) +
  geom_abline(linetype = 'dashed', intercept = 0, slope = 1) +
  geom_point(shape = 4) +
  geom_line() +
  coord_fixed() +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  labs(y = 'confidence / 100', x = 'p(correct)')
```

## Crush and shift

Another option for modifying confidence judgements is to have advisors make them on a smaller scale and then shift the resulting confidence judgements by some amount.

```{r}

agents <- c('lowConf', 'highConf')
biases <- c(0, 30)
crush <- 30
limit <- 30

n <- 1000

x <- crossing(
  i = 1:n,
  agent = agents
)

x <- x %>%
  mutate(
    bias = if_else(agent == 'lowConf', biases[1], biases[2]),
    anchor = rnorm(n(), sd = 8),
    guess = rnorm(n(), sd = 8),
    correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor),
    confidence = round(
      pmin(100, pmax(0, abs(guess - anchor) / limit * (100 - crush) + bias))
      )
)

ggplot(x, aes(x = anchor, y = guess, colour = confidence)) + 
  geom_point() +
  coord_fixed() +
  scale_x_continuous(limits = c(-100, 100)) +
  scale_y_continuous(limits = c(-100, 100)) +
  facet_wrap(~agent, labeller = label_both)

ggplot(x, aes(x = confidence, fill = agent)) + 
  geom_histogram(bins = 10, alpha = .5, position = position_identity())

x <- x %>%
  mutate(bin = map(confidence, ~ 10 * min(which(seq(10, 100, 10) >= .)))) %>%
  unnest_legacy() %>%
  nest(data = c(-bin, -agent)) %>%
  mutate(pCor = map(data, ~ mean(.x$correct))) %>%
  unnest_legacy(pCor) %>%
  unnest_legacy()

x %>%
  select(bin, agent, pCor) %>%
  unique() %>%
  ggplot(aes(y = bin / 100, x = pCor, colour = agent)) +
  geom_abline(linetype = 'dashed', intercept = 0, slope = 1) +
  geom_point(shape = 4) +
  geom_line() +
  coord_fixed() +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  labs(y = 'confidence / 100', x = 'p(correct)')

```

## Functions in confidence space

Nick had the great idea of calculating advisor confidence in confidence space, i.e. producing the desired functions on the confidence/p(correct) graph and then using p(correct) for the advisor to look up the confidence they should express. 

The first task for this is to figure out a couple of functions in confidence space which portray the desired confidence of the advisors. 

Next, we need to translate these functions such that they map onto the area of confidence space in which the advisors actual p(correct) clusters.

### Functions

Reflected $y = x^z$ ($y = x ^{1/z}$) curves look pretty good. Plotted here for $z$ = 4.

```{r}

ggplot(tibble(x = seq(.01, 1, .01)), aes(x)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  stat_function(fun = ~ . ^ (1/4), aes(colour = 'High conf')) +
  stat_function(fun = ~ . ^ 4, aes(colour = 'Low conf')) +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  coord_fixed() +
  labs(x = 'p(correct)', y = 'confidence')
```

Better, however, may well be straight lines in confidence space. Here we use $y = s(x - .5) + c$ where $s$ is the slope (titrated to 1.25 here) and $c$ is a constant used to differentiate low and high confidence advisors (here set to .1 and .4, respectively):

```{r}

ggplot(tibble(x = seq(.01, 1, .01)), aes(x)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  stat_function(fun = ~ .4 + (. - .5) * 1.25, aes(colour = 'High conf')) +
  stat_function(fun = ~ .1 + (. - .5) * 1.25, aes(colour = 'Low conf')) +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  coord_fixed() +
  labs(x = 'p(correct)', y = 'confidence')
```

Although they look a little awkward, when taken in the space of observed p(correct) values (see below) they work pretty well.

### Target part of confidence space

We should plot some information about the p(correct) of the advisors.

```{r}
n <- 100000

x <- tibble(q = 1:n) %>%
  mutate(
    anchor = rnorm(n(), sd = 8),
    guess = rnorm(n(), sd = 8),
    correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor)
    ) %>%
  mutate(bin = map(abs(guess - anchor), ~ min(which(1:100 >= .)))) %>%
  unnest_legacy() %>%
  nest(data = -bin) %>%
  mutate(pCor = map(data, ~ mean(.x$correct))) %>%
  unnest_legacy(pCor) %>%
  unnest_legacy()

ggplot(x, aes(x = bin)) + 
  geom_histogram(binwidth = 1) +
  labs(x = 'abs(guess - anchor)')

x %>% 
  group_by(bin) %>% 
  summarise(pCor = mean(pCor)) %>%
  ggplot(aes(x = bin, y = pCor)) +
  stat_summary(geom = 'point', aes(group = bin), fun.y = mean)  +
  labs(x = 'abs(guess - anchor)')

x %>% 
  group_by(bin) %>% 
  summarise(pCor = mean(pCor)) %>% 
  lm(pCor ~ bin + I(bin^2) + I(bin^3), data = .)

x %>%
  group_by(pCor) %>%
  summarise(n = n() / nrow(x) * 100) %>%
  ggplot(aes(x = pCor, y = n)) +
  geom_point() +
  labs(y = '%')
```

Advisors have a half-normal distribution on the p(correct) which they can subjectively estimate from the (absolute) difference between their guess and the anchor.

### Linear function in confidence space

Taking the linear function and adding a little random noise to each confidence judgement (SD = .05) means we get the following patterns (100,000 trials per agent):

```{r}
n <- 100000
f <- function(x, c) c + (x - .5) * 1.25

x <- tibble(q = 1:n) %>%
  mutate(
    anchor = rnorm(n(), sd = 8),
    guess = rnorm(n(), sd = 8),
    correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor)
    ) %>%
  mutate(bin = map(abs(guess - anchor), ~ min(which(1:100 >= .)))) %>%
  unnest_legacy() %>%
  nest(data = -bin) %>%
  mutate(pCor = map(data, ~ mean(.x$correct))) %>%
  unnest_legacy(pCor) %>%
  unnest_legacy()

highConf <- x %>%
  mutate(
    agent = 'HighConf',
    conf = map_dbl(pCor, ~f(., .4)) + rnorm(n(), sd = .05)
  ) 
lowConf <- x %>%
  mutate(
    agent = 'LowConf',
    conf = map_dbl(pCor, ~f(., .1)) + rnorm(n(), sd = .05)
  )

data <- rbind(highConf, lowConf) %>%
  mutate(conf = pmin(1, pmax(0, conf))) %>%
  group_by(bin, agent, pCor, conf) %>%
  summarise(correct = mean(correct))

data %>%
  ggplot(aes(x = pCor, y = conf, colour = agent)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  geom_point(alpha = .1) +
  stat_summary(geom = 'line', aes(group = agent), fun.y = mean) +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  coord_fixed() +
  labs(x = 'p(correct)', y = 'confidence')
  
```

#### Simulated advice properties

What is the distribution of confidence scale use for each advisor?

```{r}
ggplot(data, aes(x = conf, fill = agent)) + 
  geom_histogram(bins = 100, alpha = .5, position = position_identity())
```

That actually looks pretty much like what we're after! We may wonder, though, what the probability the advice came from the Low vs High conf advisor is as we observe a mystery confidence rating. This is basically what participants will have to do in the task.

```{r}

data %>% 
  mutate(conf = round(conf, 2)) %>%
  group_by(conf) %>%
  summarise(pHighConf = mean(agent == 'HighConf'), prop = n()/nrow(data)) %>%
  mutate(prop = prop / max(prop)) %>%
  ggplot(aes(x = conf, y = pHighConf)) +
  geom_line(aes(y = prop, colour = "scaled proportion of responses")) +
  geom_line(aes(colour = "p(HighConf)")) +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  coord_fixed()

```

That looks pretty amazing. We've got a slightly squiffy sigmoid where the slope looks about right and the balance point is around 50% confidence on the scale. Furthermore, that part of the scale is where there are most responses when the agents are combined (as we might expect).

#### p(correct|distance)

Advisors shouldn't objectively know their p(correct), and should instead have to estimate it from the difference between their answer and the anchor date. We want as simple a function as possible which does a good job of approximating p(correct) for a given difference.

```{r}
n <- 100000

x <- tibble(q = 1:n) %>%
  mutate(
    anchor = rnorm(n(), sd = 8),
    guess = rnorm(n(), sd = 8),
    correct = abs(guess) < abs(anchor) | sign(guess) != sign(anchor)
    ) %>%
  mutate(diff = round(abs(guess - anchor))) %>%
  mutate(bin = map(abs(guess - anchor), ~ min(which(1:100 >= .)))) %>%
  unnest_legacy() %>%
  nest(data = -diff) %>%
  mutate(pCor = map(data, ~ mean(.x$correct))) %>%
  unnest_legacy(pCor) %>%
  unnest_legacy() %>%
  # don't worry about the limit cases
  filter(pCor < .99, diff < 40)

x %>% lm(pCor ~ bin, data = .)

x %>% lm(pCor ~ bin + I(log(bin)), data = .)

x %>% lm(pCor ~ bin + I(bin ^ .2), data = .)

x %>% lm(pCor ~ bin + I(bin ^ 2), data = .)

# Should include the currently-used cubic function.

x %>%
  ggplot(aes(x = diff)) + 
  # stat_function(colour = 'black', fun = ~ .483 + .018 * . + .054 * log(.)) +
  # stat_function(colour = 'blue', fun = ~ .2276 + .015 * . + .258 * (. ^ .2)) + 
  stat_function(colour = 'red', fun = ~ .4684 + .0419 * . - .0009 * (. ^ 2)) +
  stat_function(colour = 'blue', fun = ~ pnorm(., sd = 12)) +
  geom_point(aes(y = pCor)) +
  scale_y_continuous(limits = c(.5, 1))

```

Having decided on using the pnorm function we now have to work out how to approximate it in JS. The cumulative normal distribution function supplied by math.js doesn't seem to do the trick:

```{r}

# Math.js algorithms
sdX <- function(x, sd = 12) {
  x / sd
}

erfc1 <- function(x) {
  P <- c(3.16112374387056560e00, 1.13864154151050156e02,
        3.77485237685302021e02, 3.20937758913846947e03,
        1.85777706184603153e-1)
  Q <- c(2.36012909523441209e01, 2.44024637934444173e02,
        1.28261652607737228e03, 2.84423683343917062e03)
  
  x <- sdX(x)
  x2 <- x^2
  xnum <- P[length(P)] * x2
  xden <- x2
  
  for (i in 1:length(Q)) {
    xnum <- (xnum + P[i]) * x2
    xden <- (xden + Q[i]) * x2
  }
  
  x * (xnum + P[length(Q)]) / (xden + Q[length(Q)])
}

erfc2 <- function(x) {
  P <- c(5.64188496988670089e-1, 8.88314979438837594e00,
        6.61191906371416295e01, 2.98635138197400131e02,
        8.81952221241769090e02, 1.71204761263407058e03,
        2.05107837782607147e03, 1.23033935479799725e03,
        2.15311535474403846e-8)
  Q <- c(1.57449261107098347e01, 1.17693950891312499e02,
        5.37181101862009858e02, 1.62138957456669019e03,
        3.29079923573345963e03, 4.36261909014324716e03,
        3.43936767414372164e03, 1.23033935480374942e03)
  
  x <- sdX(x)
  xnum <- P[length(P)] * x
  xden <- x
  
  for (i in 1:length(Q)) {
    xnum <- (xnum + P[i]) * x
    xden <- (xden + Q[i]) * x
  }
  
  r <- (xnum + P[length(Q)]) / (xden + Q[length(Q)])
  x2 <- (x * 16) / 16  # ?? this is what math.js has
  d <- (x - x2) * (x + x2);
  1 - (exp(-x2 * x2) * exp(-d) * r)
}

erfc3 <- function(x) {
  P <- c(3.05326634961232344e-1, 3.60344899949804439e-1,
        1.25781726111229246e-1, 1.60837851487422766e-2,
        6.58749161529837803e-4, 1.63153871373020978e-2)
  Q <- c(2.56852019228982242e00, 1.87295284992346047e00,
        5.27905102951428412e-1, 6.05183413124413191e-2,
        2.33520497626869185e-3)
  
  x <- sdX(x)
  x2 <- 1 / (x ^ 2)
  xnum <- P[length(P)] * x2
  xden <- x2
  
  for (i in 1:length(Q)) {
    xnum <- (xnum + P[i]) * x2
    xden <- (xden + Q[i]) * x2
  }
  
  r <- x2 * (xnum + P[length(Q)]) / (xden + Q[length(Q)])
  
  sqrtpi <- 5.6418958354775628695e-1 # this is so NOT the sqrt(pi)
  
  r <- (sqrtpi - r) / x
  
  x2 <- (x * 16) / 16  # ?? this is what math.js has
  d <- (x - x2) * (x + x2);
  1 - (exp(-x2 * x2) * exp(-d) * r)
}

js <- c(0, 0.0938143842450717, 0.18633628423320808, 0.2763263901682369, 0.3626481117660628, 0.4443102097172054, 0.5204998778130465, 0.5906045137900813, 0.6542214138488396, 0.7111556336535152, 0.7614071706835646, 0.8051493513911305, 0.8427007929497148, 0.8744935285625308, 0.9010398459805942, 0.9229001282564582, 0.9406535612080801, 0.9548730511113239, 0.9661051464753108, 0.9748552388266426, 0.981577874545901) %>%
  enframe() %>%
  transmute(x = name - 1, js = value)

ggplot(js, aes(x, js)) +
  geom_vline(xintercept = 0.46875, linetype = 'dotted') +
  geom_vline(xintercept = 4, linetype = 'dashed') + 
  geom_point() +
  stat_function(colour = 'blue', fun = ~pnorm(., sd = 12)) +
  stat_function(fun = erfc1) +
  stat_function(fun = erfc2, linetype = 'dotted') +
  stat_function(fun = erfc3, linetype = 'dashed') +
  scale_y_continuous(limits = c(0, 1))

```

In the end we solve this with a lookup table taken from pnorm(seq(0, 4, .01)).