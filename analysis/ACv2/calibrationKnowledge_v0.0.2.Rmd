---
title: "Confidence estimation"
author: "[Matt Jaquiery](https://github.com/mjaquiery) ([matt.jaquiery@psy.ox.ac.uk](mailto:matt.jaquiery@psy.ox.ac.uk))"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
    css: ../src/writeUp.css
    includes:
      after_body: ../src/toc_menu.html
  html_notebook:
    toc: yes
    toc_depth: 3
    css: ../src/writeUp.css
    includes:
      after_body: ../src/toc_menu.html
editor_options:
  chunk_output_type: inline
---

December 2019

[Script run `r Sys.time()`]


```{r prematter, include = F}

library(tidyverse)
library(scales)
library(broom)
library(BayesFactor)
library(prettyMD)
library(knitr)
library(parallel)
library(ez)

opts_chunk$set('echo' = F)

set.seed(20191216)

# Plot setup
theme_set(theme_light() + 
            theme(panel.grid = element_blank(),
                  legend.position = 'top'))

```

```{r loadData, include = F}

rDir <- "http://localhost/ExploringSocialMetacognition/data/public/"
testData <- T

studyVersion <- "0-0-16"
studyName <- "calibrationKnowledge"

exclude <- list(
  maxTrialRT = 60000,    # trials take < 1 minute
  minTrials = 11,        # at least 11 trials completed
  minChangeRate = .1     # some advice taken on 10%+ of trials
  ) 

skipLoadData <- F

source("src/02_Exclusions.R")

if (testData) {
  # Construct some models of participant behaviour on the ‘prefer worst known to
  # unknown’, ‘treat unknown as worst known’, and ‘weight advice weights
  # according to how likely advice of a given confidence was to come from each
  # advisor’
  source("src/sim-confidence-estimation.R")
  model <- simulateCK(
    AdvisedTrial,
    agentInsensitivitySD = 8,
    agentConfidence = 2,
    agentConfidenceSD = 4,
    agentEgoBias = .7, 
    agentEgoBiasSD = .2,
    agentEffectSize = .1,
    agentEffectSizeSD = .1,
    strategy = 'PreferWorst'
    )
  AdvisedTrial <- model$trials
  decisions <- byDecision(AdvisedTrial)
}

```

# Introduction

Observations from [evolutionary models](https://github.com/oxacclab/EvoEgoBias) show that egocentric discounting is a successful strategy in environments where advisors cannot be clear on how advisors' expressed confidence relates to their actual confidence. We reason that human participants may show a sensitivity to these contextual factors underlying advice-taking and respond to them in a rational manner. To test the effects of known versus unknown confidence representations, we manipulated whether participants knew which of two advisors was giving them advice. Participants performed a block of 9 trials to get acquainted with each of two advisors, one who had high confidence and one who had low confidence (both were equally accurate). The advisors introduced themselves exhibiting their confidence. Participants then performed 20 trials where no feedback was given and advice came from one of the two advisors they had previously encountered. In some of these trials the advice was labelled as coming from the advising advisor, in others it was shown as coming from an unspecified one of the two advisors.

We hypothesised that participants would show greater sensitivity to the confidence of advice when they knew the identify of the advisor.

# Method

The experimental code is available on [GitHub](https://github.com/oxacclab/ExploringSocialMetacognition), and the experiment can be performed by visiting [https://acclab.psy.ox.ac.uk/~mj221/ESM/ACBin/ce.html](https://acclab.psy.ox.ac.uk/~mj221/ESM/ACBin/ck.html?PROLIFIC_PID=WriteUp). 

# Results

## Exclusions

```{r exclusions}

if (testData) {
  print("NOTE: Testing (simulated) data!!!!")
}

tmp <- suppressWarnings(left_join(exclusions, okayIds, by = "pid"))

tmp$condition <- factor(tmp$condition, labels = c("highFirst",
                                                  "lowFirst"))

table(tmp$excluded, tmp$condition)

# Test accuracy of the labels
AdvisedTrial %>% 
  group_by(pid, block, advisor0idDescription) %>% 
  filter(block == 2) %>% 
  summarise(n()) %>% 
  left_join(tmp, by = 'pid') %>% 
  ungroup() %>%
  select(advisor0idDescription, condition) %>%
  mutate(ok = if_else(advisor0idDescription == 'lowConf',
                      condition == 'lowFirst',
                      condition == 'highFirst')) %>%
  pull(ok) %>%
  all() %>%
  expect_equal(T)

```

```{r data visualisation variables}
# Add some variables which we can use for plotting prettily later

AdvisedTrial <- AdvisedTrial %>%
  mutate(Hybrid = if_else(advisor0name == '?', 'Hybrid', 'Labelled'),
         Advisor = capitalize(as.character(advisor0idDescription)),
         Feedback = if_else(feedback, "With Feedback", "No feedback"))

decisions <- decisions %>% 
  mutate(Hybrid = if_else(advisor0name == '?', 'Hybrid', 'Labelled'),
         Advisor = capitalize(as.character(advisor0idDescription)),
         Feedback = if_else(feedback, "With Feedback", "No feedback"),
         Decision = capitalize(decision))
```

Our final participant list consists of `r length(unique(AdvisedTrial$pid))` participants who completed an average of `r num2str(mean(aggregate(advisor0 ~ pid, AdvisedTrial, length)$advisor0))` trials each, of which an average of `r num2str(mean(aggregate(advisor0 ~ pid, AdvisedTrial[!AdvisedTrial$feedback, ], length)$advisor0))` had no feedback.

## Task performance

First we offer a characterisation of the task, to provide the reader with a sense of how the participants performed. 

### Decisions

Participants offered estimates of whether various events took place before or after a given year. The correct answers were always between 1900 and 2000. Participants answered by selecting a point on one of two confidence bars, with the choice of bar indicating the chosen answer. 

#### Correctness

```{r accuracy}

decisions %>% peek(responseCorrect, decision) %>%
  num2str.tibble(isProportion = T, precision = 3)

decisions %>% filter(feedback == T) %>% 
  peek(responseCorrect, decision) %>% 
  num2str.tibble(isProportion = T, precision = 3) %>%
  cbind(feedback = T)

```

```{r accuracyGraph}

tmp <- decisions %>% group_by(pid, Decision, Feedback) %>%
  do(correct = mean_cl_normal(.$responseCorrect)) %>%
  unnest(correct) %>%
  transmute(pid, Decision, Feedback,
            pCorrect = y, 
            ciLow = ymin,
            ciHigh = ymax)

ggplot(tmp, 
       aes(x = Decision, y = pCorrect)) +
  geom_hline(yintercept = .5, linetype = 'dashed') +
  geom_violin(alpha = .15, colour = NA, aes(fill = Decision)) +
  geom_boxplot(fill = "white", outlier.color = NA, aes(colour = Decision),
               width = .25, size = 1.25) +
  geom_line(alpha = .25, aes(group = pid)) + 
  scale_y_continuous(limits = c(0, 1)) +
  labs(y = "P(Response correct)") +
  facet_grid(~Feedback)

# caption = "Probability of correct responses on initial estimates and final decisions. Lines show individual participant means, while violins and boxplots give distributions. The dashed line shows chance performance."

```

### Timing

We can look at the response time - the difference between the time the response is opened and the time the response is received.  

```{r time}

decisions$rt <- decisions$responseTimeEstimate - decisions$timeResponseOpen

decisions %>% peek(rt, decision) %>% 
  mutate_if(is.numeric, round)

```

```{r timeGraph}

tmp <- decisions %>% group_by(pid, Decision) %>% 
  summarise(rt = mean(rt))

tmp %>%
  ggplot(aes(x = Decision, y = rt)) +
  geom_violin(alpha = .15, colour = NA, aes(fill = Decision)) +
  geom_boxplot(fill = "white", outlier.color = NA, aes(colour = Decision),
               width = .25, size = 1.25) +
  geom_line(alpha = .25, aes(group = pid)) + 
  labs(y = "Response time (ms)") 

# caption = "Response times for initial estimates and final decisions. Lines show individual participant means, while violins and boxplots give distributions."

```

### Summary {.summary}

Participants' initial decisions were only slightly better than chance. Their final decisions were substantially better, indicating a reasonably high rate of switching from one answer to the other following advice. The time taken to answer each question was consistent with previous experiments.

## Metacognitive performance

### Confidence

Each answer bar allowed the participant to express their confidence in that answer by selecting a higher point on the bar for a higher confidence, in a range of 0-100% for each decision.

```{r confidence}

decisions %>% peek(responseConfidence, decision) %>%
  num2str.tibble(isProportion = T, precision = 1)

decisions %>% filter(feedback == T) %>% 
  peek(responseConfidence, decision) %>% 
  num2str.tibble(isProportion = T, precision = 3) %>%
  cbind(feedback = T)

```

```{r confidence graph}

tmp <- decisions %>% group_by(pid, Decision, Feedback) %>%
  do(confidence = mean_cl_normal(.$responseConfidence)) %>%
  unnest(confidence) %>%
  transmute(pid, Decision, Feedback,
            confidence = y, 
            ciLow = ymin,
            ciHigh = ymax)

ggplot(tmp, 
       aes(x = Decision, y = confidence)) +
  geom_violin(alpha = .15, colour = NA, aes(fill = Decision)) +
  geom_boxplot(fill = "white", outlier.color = NA, aes(colour = Decision),
               width = .25, size = 1.25) +
  geom_line(alpha = .25, aes(group = pid)) + 
  scale_y_continuous(limits = c(0, 100)) +
  labs(y = "Confidence") +
  facet_grid(~Feedback)

# caption = "Confidence of initial estimates and final decisions. Lines show individual participant means, while violins and boxplots give distributions."

```

### Relationship between confidence and p(correct)

Participants indicated the confidence in their decisions simultaneously with the decisions themselves. We can thus explore how well a participant's confidence signals their accuracy. We provide only a brief examination here where normalised responses are split into high and low confidence for each participant, and the accuracies of the two categories are compared. This is done separately for first and last decisions.

```{r confidence normalisation}

decisions <- decisions %>% 
  group_by(pid, decision) %>% 
  dplyr::mutate(zConf = scale(responseConfidence)) %>%
  ungroup() 

```

```{r confidence binary split}

tmp <- decisions %>% 
  mutate(highConf = zConf > 0) %>%
  group_by(pid, decision, Decision, highConf) %>%
  summarise(pCorrect = mean(responseCorrect)) %>%
  filter(!is.na(highConf)) %>%
  group_by(pid, decision, Decision) %>%
  spread(highConf, pCorrect) %>%
  mutate(pCorrectDiff = `TRUE` - `FALSE`)

drop <- length(unique(tmp$pid)) != length(unique(decisions$pid))
if (drop > 0) {
  print(paste0("Dropping ", drop, " rows from analysis for unstandardizable confidence."))
}

tmp %>% 
  peek(pCorrectDiff, decision) %>% 
  num2str.tibble(isProportion = T, precision = 3)

print("p(correct|high confidence) - p(correct|low confidence) for initial estimates")
ttestBF(tmp$pCorrectDiff[tmp$decision == "first"])
print("p(correct|high confidence) - p(correct|low confidence) for final decisions")
ttestBF(tmp$pCorrectDiff[tmp$decision == "last"])

```

```{r confidence binary split plot}

tmp %>% 
ggplot(aes(x = Decision, y = pCorrectDiff)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  geom_violin(alpha = .15, colour = NA, aes(fill = Decision)) +
  geom_boxplot(fill = "white", outlier.color = NA, aes(colour = Decision),
               width = .25, size = 1.25) +
  geom_line(alpha = .25, aes(group = pid)) + 
  labs(y = "P(Correct | sure) - P(Correct | unsure)") +
  scale_y_continuous(limits = c(-1, 1))  

# caption = "Difference in the probability of correct responses on initial estimates and final decisions when made with high versus low confidence. Lines show individual participant means, while violins and boxplots give distributions. The dashed line shows chance performance."
 
```

### Summary {.summary}

Participants' answers were generally around the midpoint on the scale, with a fair amount of variation between participants. Confidence in final decisions did not appear to be consistently higher than initial estimates, although this is unsurprising given the final decisions are not split by whether the advisor agreed with the initial decision.

The relationship between confidence and the probability of being correct is essentially zero for initial estimates, indicating that participants are guessing on initial decisions. Final decisions did show a relationship where higher confidence in decisions was indicative of a greater probability of being correct, presumably because participants' confidence was readily affected by advice.

## Advisor performance

Participants in should get an appropriate experience of each advisor in the feedback condition. This means that the accuracy and metacognitive sensitivity of the advisors should be balanced, while the confidence (metacognitive bias) is not. 

### Accuracy

```{r adviceAccuracy}

AdvisedTrial$advisor0accurate <- ifelse(
  is.na(AdvisedTrial[, paste0(advisorNames[1], ".accurate")]),
  pull(AdvisedTrial[, paste0(advisorNames[2], ".accurate")]),
  pull(AdvisedTrial[, paste0(advisorNames[1], ".accurate")])
)

AdvisedTrial$advisor0agree <- ifelse(
  is.na(AdvisedTrial[, paste0(advisorNames[1], ".agree")]),
  pull(AdvisedTrial[, paste0(advisorNames[2], ".agree")]),
  pull(AdvisedTrial[, paste0(advisorNames[1], ".agree")])
)

tmp <- AdvisedTrial %>% 
  filter(feedback) %>%
  group_by(pid, Advisor) %>%
  summarise(advisorAccuracy = mean(advisor0accurate),
            advisorAgree = mean(advisor0agree)) 

tmp %>% 
  group_by(Advisor) %>%
  summarise(advisorAccuracy = mean(advisorAccuracy),
            advisorAgree = mean(advisorAgree)) %>%
  num2str.tibble(isProportion = T, precision = 3)

```

```{r adviceAccuracyGraph}

tmp %>% 
  dplyr::rename(`p(correct)` = advisorAccuracy,
                `p(agree)` = advisorAgree) %>%
  gather("var", "value", `p(correct)`:`p(agree)`) %>%
  mutate(var = capitalize(var)) %>%
  ggplot(aes(x = Advisor, y = value)) +
  geom_hline(yintercept = .5, linetype = 'dashed') +
  # geom_hline(yintercept = .75, linetype = 'dashed', colour = 'lightgrey') +
  geom_violin(alpha = .15, colour = NA, aes(fill = Advisor)) +
  geom_boxplot(fill = "white", outlier.color = NA, aes(colour = Advisor),
               width = .25, size = 1.25) +
  geom_line(alpha = .25, aes(group = pid)) + 
  labs(y = "Mean") +
  scale_y_continuous(limits = c(0, 1)) + 
  scale_colour_discrete(h.start = 45) + 
  scale_fill_discrete(h.start = 45) +
  facet_wrap(~var)
  
# caption = "Probability of agreement (left panel) and correct responses (right panel) for advice from the two advisors. Lines show individual participant means, while violins and boxplots give distributions. The dashed line shows chance level."
  
```

### Advisor confidence

The advisors differ by design in their confidence, so participants should experience these differences.

```{r advisor confidence}

tmp <- AdvisedTrial %>% 
  filter(feedback) %>%
  group_by(pid, Advisor) %>%
  summarise(confidence = mean(advisor0adviceConfidence))

tmp %>% 
  group_by(Advisor) %>%
  summarise(confidence = mean(confidence)) %>%
  num2str.tibble(precision = 1)


```

```{r advisor confidence graph}

tmp %>%
  ggplot(aes(x = Advisor, y = confidence)) +
  geom_violin(alpha = .15, colour = NA, aes(fill = Advisor)) +
  geom_boxplot(fill = "white", outlier.color = NA, aes(colour = Advisor),
               width = .25, size = 1.25) +
  geom_line(alpha = .25, aes(group = pid)) + 
  scale_y_continuous(limits = c(0, 100)) +
  scale_colour_discrete(h.start = 45) + 
  scale_fill_discrete(h.start = 45) +
  labs(y = 'Mean advisor confidence')

# caption = "Mean advisor confidence for each advisor during the training phase. Lines show the mean experience of an individual participant, while violins and boxplots show the distributions."

```

#### Individual participants' experience

We should take a look at a handful of specific distributions experienced by individual participants to ensure the individual-level view tallies with the sample view. 

```{r advisor confidence by participant}

tmp <- AdvisedTrial %>%
  filter(feedback) %>%
  select(pid, Advisor, Confidence = advisor0adviceConfidence) %>%
  nest(data = c(Advisor, Confidence)) %>%
  # sample_n(6) %>%
  unnest_legacy()

ggplot(tmp, aes(x = Advisor, y = Confidence, colour = Advisor)) +
  geom_violin() +
  geom_point(position = position_jitter(.1), alpha = .5) + 
  scale_colour_discrete(h.start = 45) + 
  facet_wrap(~pid) +
  theme(strip.text = element_blank())

# caption = "Individual participant experience of the advisors during the familiarity phase. Each point shows a single trial, while the violins indicate the distribution."
  
ggplot(tmp, aes(x = Advisor, y = Confidence, colour = Advisor)) +
  geom_violin() +
  geom_point(position = position_jitter(width = .1), alpha = .1) +
  scale_colour_discrete(h.start = 45)

# caption = "Overall advice of advisors during the familiarity phase. Each point shows a single trial, while the violins indicate the distribution."

```

### Distance

Distance is the continuous version of agreement - the difference along the confidence scale between the advice and the initial estimate. Where different scales are endorsed, the difference is the combination of how sure the participant was on one scale plus how sure the advisor was on the other.

```{r adviceDistance}

AdvisedTrial$advisor0distance <- ifelse(
  is.na(AdvisedTrial[, paste0(advisorNames[1], ".distance")]),
  pull(AdvisedTrial[, paste0(advisorNames[2], ".distance")]),
  pull(AdvisedTrial[, paste0(advisorNames[1], ".distance")])
)
AdvisedTrial$advisor0distanceFinal <- ifelse(
  is.na(AdvisedTrial[, paste0(advisorNames[1], ".distanceFinal")]),
  pull(AdvisedTrial[, paste0(advisorNames[2], ".distanceFinal")]),
  pull(AdvisedTrial[, paste0(advisorNames[1], ".distanceFinal")])
)

tmp <- AdvisedTrial %>% 
  filter(feedback) %>%
  group_by(pid, Advisor) %>%
  summarise(adviceDistance = mean(advisor0distance)) 

tmp %>% 
  group_by(Advisor) %>%
  summarise(adviceDistance = mean(adviceDistance)) %>%
  num2str.tibble(precision = 1)

```

```{r adviceDistanceGraph}

tmp %>% 
  ggplot(aes(x = Advisor, y = adviceDistance)) +
  geom_violin(alpha = .15, colour = NA, aes(fill = Advisor)) +
  geom_boxplot(fill = "white", outlier.color = NA, aes(colour = Advisor),
               width = .25, size = 1.25) +
  geom_line(alpha = .25, aes(group = pid)) + 
  scale_colour_discrete(h.start = 45) + 
  scale_fill_discrete(h.start = 45) +
  scale_y_continuous(limits = c(0, 200)) +
  labs(y = 'Advice distance')

# caption = "Distance in scale points between the participants' initial estimates and the advisors' advice. Lines show individual participant means, while violins and boxplots give distributions."

```

### Summary {.summary}

The advisors' performances were within the expected ranges for both the probability and extent of agreement with the participants and the objective accuracy of their advice. The advisors didn't differ substantially from one another in any of these aspects.

### Influence

The measure of influence is the extent to which a participant's confidence moves in the expected direction as a function of the advice (increasing when agreed with, decreasing when disagreed with).

Influence is the primary outcome measure. It is likely to differ between high and low confidence advisors because people tend to find high-confidence advice more persuasive. Relevant for our hypotheses, it may differ between hybrids and labelled advisors.

```{r influence}

AdvisedTrial$advisor0influence <- 
  unlist(sapply(1:nrow(AdvisedTrial),
                function(i) 
                  AdvisedTrial[i, 
                               paste0(AdvisedTrial$advisor0idDescription[i], 
                                      ".influence")]))

tmp <- AdvisedTrial %>% 
  filter(!feedback) %>%
  mutate(hybrid = advisor0name == '?') %>%
  group_by(pid, advisor0idDescription, hybrid) %>%
  summarise(advisorInfluence = mean(advisor0influence)) 

tmp %>% 
  group_by(advisor0idDescription, hybrid) %>%
  summarise(advisorInfluence = mean(advisorInfluence)) %>%
  num2str.tibble(precision = 1)

```

```{r influenceGraph}

tmp %>% 
  mutate(Advisor = capitalize(paste0(advisor0idDescription, if_else(hybrid, '?', '')))) %>%
  ggplot(aes(x = Advisor, y = advisorInfluence)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  geom_violin(alpha = .15, colour = NA, aes(fill = Advisor)) +
  geom_boxplot(fill = "white", outlier.color = NA, aes(colour = Advisor),
               width = .25, size = 1.25) +
  geom_line(alpha = .25, aes(group = pid)) + 
  scale_colour_discrete(h.start = 45) + 
  scale_fill_discrete(h.start = 45) +
  scale_y_continuous(limits = c(-100, 100)) +
  labs(y = 'Advisor influence')

# caption = "Influence of the advisors on test trials. Advisors with their own names show data from labelled trials, while those with a '?' show data from trials where the advice was given a hybrid label. Lines show means for individual participants, while violins and boxplots show distributions. The dashed line indicates zero influence."

```

#### Influence scatter plots

```{r}

AdvisedTrial %>%
  filter(!feedback) %>%
  mutate(Advisor = if_else(advisor0name == '?', 
                           'Hybrid', 
                           capitalize(as.character(advisor0idDescription)))) %>%
  ggplot(aes(x = advisor0adviceConfidence, 
             y = advisor0influence, 
             colour = Advisor)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  geom_point(alpha = .25) +
  geom_smooth(aes(group = Advisor),
               method = 'lm', se = F, fullrange = T) +
  stat_smooth(aes(group = paste0(pid, Advisor, sep = '.')),
              geom = 'line', method = 'lm', alpha = .25) +
  scale_colour_manual(values = hue_pal(h.start = 45)(4)[1:3]) + 
  labs(x = 'Advisor confidence', y = 'Advisor influence')

# caption = "Relationship between advisor confidence and advisor influence. Dots show individual trials, while faint lines link a participant's trials for a given advisor. The heavy lines show data for each advisor aggregated over all participants. The dashed black line indicates zero influence."

```

#### Influence distribution

It's good to keep a general eye on the distribution of weight-on-advice on a trial-by-trial basis. 

```{r influenceDistribution}

AdvisedTrial %>% 
  filter(!feedback) %>%
  ggplot(aes(advisor0influence, colour = Advisor, fill = Advisor)) + 
  geom_histogram() +
  facet_grid(Hybrid ~ Advisor) +
  scale_colour_discrete(h.start = 45) + 
  scale_fill_discrete(h.start = 45) +
  labs(y = 'Trial count', x = 'Advisor influence')

# caption = "Histogram of advisor influence by advisor and hybrid status for test trials."

```

#### Is initial accuracy or initial confidence a better predictor of influence?

```{r influence correlations}

tmp <- AdvisedTrial %>% 
  select(pid, responseCorrect, responseConfidence, advisor0influence) %>%
  nest(data = -pid) %>%
  mutate(
    accBF = map(data, ~ correlationBF(.x$responseCorrect, 
                                    .x$advisor0influence)),
    acc.BF = map(accBF, ~ exp(.@bayesFactor$bf)),
    conBF = map(data, ~ correlationBF(.x$responseConfidence, 
                                    .x$advisor0influence)),
    con.BF = map(conBF, ~ exp(.@bayesFactor$bf)),
    acc = map(data, ~ cor.test(as.numeric(.x$responseCorrect), 
                               .x$advisor0influence)), 
    acc = map(acc, tidy),
    con = map(data, ~ cor.test(.x$responseConfidence, .x$advisor0influence)), 
    con = map(con, tidy)
  ) %>% 
  unnest(acc, .sep = ".") %>%
  unnest(con, .sep = ".") %>%
  unnest(acc.BF, con.BF)

tmp <- bind_rows(
  tmp %>% 
    select_at(vars(starts_with('acc'))) %>%
    rename_all(~ str_replace(., 'acc\\.(.+)', '\\1')) %>%
    mutate(property = 'accuracy'),
  tmp %>% 
    select_at(vars(starts_with('con'))) %>%
    rename_all(~ str_replace(., 'con\\.(.+)', '\\1')) %>%
    mutate(property = 'confidence')
)

tmp %>% 
  group_by(property) %>%
  summarise_if(is.numeric, mean, na.rm = T)

```

### Summary {.summary}

The influence of the advisors (formally tested below) did not show obvious differences between the advisors. while many participants were slightly more influenced by the single advisor, the participants with the largest differences between advisors were influenced more by the mass advisor. As usual, the vast majority of individual trials showed almost no influence of advice; this is somewhat surprising given that participants' initial answers were barely more accurate than guessing.

## Manipulation checks

Participants should learn the advisor mappings during the course of the experiment. This means that they should treat the low- and high-confidence advisors' advice differently when those advisors express medium confidence on the scale. Specifically, they should be more highly influenced by the low-confidence advisor than by the high-confidence advisor.

```{r}

boundaries <- c(min(AdvisedTrial$highConf.adviceConfidence, na.rm = T),
                max(AdvisedTrial$lowConf.adviceConfidence, na.rm = T))

tmp <- AdvisedTrial %>%
  filter(!feedback,
         Hybrid == 'Labelled',
         advisor0adviceConfidence >= boundaries[1],
         advisor0adviceConfidence <= boundaries[2])

ggplot(tmp, aes(x = advisor0adviceConfidence, y = advisor0influence, colour = Advisor)) + 
  geom_hline(yintercept = 0, linetype = 'dashed') +
  stat_smooth(aes(group = paste0(pid, Advisor, sep = '.')),
              geom = 'line', method = 'lm', alpha = .25) +
  geom_point(alpha = .25) +
  geom_smooth(aes(group = Advisor),
               method = 'lm', se = F, fullrange = T) +
  scale_y_continuous(limits = c(-100, 100)) +
  scale_colour_discrete(h.start = 45) + 
  scale_fill_discrete(h.start = 45) +
  facet_wrap(~Advisor) +
  labs(x = 'Advisor confidence', y = 'Advisor influence') 

# caption = "Relationship between advisor confidence and advisor influence for labelled advisors during test trials. Dots show individual trials, while faint lines show individual participants' linear model fits. Heavy lines show linear fits aggregated over all participants, while the black dashed line shows zero influence."

```

## Advisor preferences

In the hypothesis tests we need to know which advisor is most influential for each participant. We explore this influence over only those trials on which the participants receive feedback.

```{r favourite advisors}

# Find favourite advisor where confidence is balanced
tmp <- AdvisedTrial %>%
  filter(feedback,
         advisor0adviceConfidence >= boundaries[1],
         advisor0adviceConfidence <= boundaries[2]) %>%
  group_by(pid, advisor0id) %>%
  summarise(influence = mean(advisor0influence)) %>%
  spread(advisor0id, influence) %>%
  group_by(pid) %>%
  summarise(favouriteAdvisorId = if_else(`1` > `2`, 1, 2))

AdvisedTrial <- AdvisedTrial %>% left_join(tmp, by = 'pid')

# Plot influence for feedback trials
tmp <- AdvisedTrial %>% 
  filter(feedback,
         advisor0adviceConfidence >= boundaries[1],
         advisor0adviceConfidence <= boundaries[2]) %>%
  group_by(pid, Advisor) %>%
  summarise(advisorInfluence = mean(advisor0influence)) %>%
  spread(Advisor, advisorInfluence) %>%
  mutate(Favourite = if_else(LowConf > HighConf, 'LowConf', 'HighConf')) %>%
  gather("Advisor", "advisorInfluence", LowConf:HighConf)

tmp %>% 
  ggplot(aes(x = Advisor, y = advisorInfluence)) +
  geom_hline(yintercept = 0, linetype = 'dashed') + 
  geom_violin(alpha = .15, colour = NA, aes(fill = Advisor)) +
  geom_boxplot(fill = "white", outlier.color = NA, aes(colour = Advisor),
               width = .25, size = 1.25) +
  geom_line(alpha = .25, size = 1, aes(group = pid, linetype = Favourite)) + 
  scale_colour_discrete(h.start = 45) + 
  scale_fill_discrete(h.start = 45) +
  scale_y_continuous(limits = c(-100, 100)) +
  labs(y = 'Advisor influence')

# caption = "Advisor influence by advisor on familiarity trials where the advisor's confidence was within the medium-confidence window. Lines show individual participant's means, with the line type indicating which advisor had the higher mean influence for that participant on these trials. Violins and boxplots show distributions, while the full width black dashed line indicates zero influence."

tmp %>%
  group_by(pid) %>% 
  summarise(favourite = unique(Favourite)) %>%
  group_by(favourite) %>%
  summarise(n())

```

## Hypothesis testing

The hypotheses being tested here are:  

1. Participants will place different weights on their least favourite advisor when they know that advisor's identity compared to when that advisor is labelled as a hybrid (controlling for confidence).

```{r h1}
  
# Test
tmp <- AdvisedTrial %>%
  filter(!feedback, 
         advisor0id != favouriteAdvisorId,
         advisor0adviceConfidence >= boundaries[1],
         advisor0adviceConfidence <= boundaries[2]) %>%
  group_by(pid, Hybrid) %>%
  summarise(influence = mean(advisor0influence)) %>%
  spread(Hybrid, influence)

pids <- 
  tmp %>% 
  gather("advisor", "influence", -pid) %>%
  filter(is.na(influence)) %>%
  pull(pid)

if (length(pids)) {
  warning("Removing ", length(pids), " participants with NAs in advisor influence. Ids: ", paste0(pids, collapse = ", "))
  tmp <- tmp %>% filter(!(pid %in% pids))
}

cat(md.ttest(tmp$Labelled, tmp$Hybrid, paired = T, 
             labels = c('*M*|Labelled', '*M*|Hybrid')))

# Graph
tmp %>% 
  gather("advisor", "influence", -pid) %>%
  left_join(
    AdvisedTrial %>% 
      group_by(pid) %>% 
      filter(advisor0id != favouriteAdvisorId) %>%
      summarise(nonfavourite = unique(Advisor)),
    by = 'pid') %>%
  rename(Advisor = advisor) %>%
  ggplot(aes(x = Advisor, y = influence)) +
  geom_violin(alpha = .15, colour = NA, aes(fill = Advisor)) +
  geom_boxplot(fill = "white", outlier.color = NA, aes(colour = Advisor),
               width = .25, size = 1.25) +
  geom_line(alpha = .25, size = 1, aes(group = pid, linetype = nonfavourite)) + 
  scale_colour_discrete(h.start = 135) + # match colours with hybrid green above
  scale_fill_discrete(h.start = 135) +
  scale_y_continuous(limits = c(-100, 100)) +
  scale_linetype_discrete(name = 'Least favourite advisor') +
  labs(x = 'Advisor presentation', y = 'Advisor influence')

# caption = "Advice influence for the least influential advisor in the critical trials. Lines show individual participants' means, while box plots and violins show distributions. Labelled trials are those where the advisor's identity is displayed to the participant, while hybrid trials are those where the advice could be coming from either advisor. The line types show the identity of the least advisor whose influence is plotted for that participant."

```

### Summary {.summary}

The null model in which the advisors' advice is the same is 5x more likely than the alternative given the data observed. It would be appropriate to conclude that this manipulation does not produce a meaningful difference in advice processing.

## Exploration

### ANOVA

The experiment is structured suitably for a neat ANOVA comparing the effects of advisor and advisor labelling.

```{r anova}

tmp <- AdvisedTrial %>% 
  dplyr::filter(feedback == F) %>%
  mutate(hybrid = factor(advisor0name == '?')) %>%
  group_by(pid, advisor0idDescription, hybrid) %>% 
  summarise(influence = mean(advisor0influence)) %>% 
  ezANOVA(dv = influence,
          wid = pid, 
          within = c(hybrid, advisor0idDescription))

tmp

if (testData) {
  for (s in c('LeastPref', 
              'PreferWorst'#, 
              # 'LikelihoodWeighted'
              )) {
    print(paste0('=== ', s, ' ==='))
    tmp <- AdvisedTrial %>% 
      dplyr::filter(feedback == F) %>%
      mutate(advisor0agree = as.logical(advisor0agree))
    tmp$r <- pull(tmp, paste0('responseConfidenceFinal', s))
    tmp <- tmp %>% 
      mutate(
        influence = case_when(
          advisor0agree & r >= 0 ~ r - responseConfidence,
          advisor0agree & r < 0 ~ -(responseConfidence + r),
          !advisor0agree & r >= 0 ~ -(responseConfidence - r),
          !advisor0agree & r < 0 ~ responseConfidence + r
        )
    )
    tmp %>%
      mutate(hybrid = factor(advisor0name == '?')) %>%
      group_by(pid, advisor0idDescription, hybrid) %>% 
      summarise(influence = mean(influence)) %>% 
      ezANOVA(dv = influence,
              wid = pid, 
              within = c(hybrid, advisor0idDescription)) %>%
      print()
  }
}

```

# Conclusions {.summary}

!TODO[Conclusions]

# Credits 

## Acknowledgements

Thanks as always to Nick Yeung and the other folks at the [ACC Lab](https://www.psy.ox.ac.uk/research/attention-cognitive-control-lab).

## R Packages

```{r results = 'asis'}
# list packages
packageNames <- (.packages())
# don't include very core package
packageNames <- packageNames[!(packageNames %in% 
                                 rownames(installed.packages(
                                   priority = "base")))]
# but do include the base package
packageNames <- c("base", packageNames)
out <- NULL
for (p in packageNames) {
  out <- rbind(out, data.frame('Package' = p, 
                               'Citations' = paste(format(citation(p), 
                                                          style = 'textVersion'), 
                                                   collapse = '<br/><br/>')))
}

kable(out)
```

## Funding

Matt Jaquiery is funded by a studentship from the [Medical Research Council](https://mrc.ukri.org/) (reference 1943590) and the University of Oxford [Department of Experimental Psychology](https://www.psy.ox.ac.uk/) (reference 17/18_MSD_661552).

## Technical details  

```{r results = 'hold'}
cat(paste('Time stamp:', Sys.time(), '\n\n'))
cat('Runtime \n')
proc.time()
cat('\n')
sessionInfo()
```